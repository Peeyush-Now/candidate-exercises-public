{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook loads data from a CSV, AVRO and JSON files and combines them in a single deduplicated dataframe and answers some questions.\n",
    "\n",
    "URL(https://github.com/implydata/candidate-exercises-public/blob/master/Customer%20Success/SA/DataEngineeringProject/Applicant/) for the challenge and datasets below.\n",
    "\n",
    "The notebook uses the following \n",
    "python <= 3.10 \n",
    "Jupyter Notebook\n",
    "Pandas *\n",
    "fastavro *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Challenge summary replicated from the Github URL.\n",
    "\n",
    "There are three source files. CityListA.json, CityListB.avro, and CityListC.csv. They each contain data in three columns:\n",
    "\n",
    "Schema for the files\n",
    "name:string\n",
    "code:string\n",
    "Population:long\n",
    "\n",
    "The goal is to combine the files, eliminating any duplicates and write to a single .CSV file sorted alphabetically by the city name. \n",
    "\n",
    "Q1: What is the count of all rows?\n",
    "Q2: What is the city with the largest population?\n",
    "Q3: What is the total population of all cities in Brazil (CountryCode == BRA)?\n",
    "Q4: What changes could be made to improve your program's performance.\n",
    "Q5: How would you scale your solution to a much larger dataset (too large for a single machine to store)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "'''\n",
    "In this snippet, a file handle for CSV is created and used as an iterator to read 10K records at a time. \n",
    "While we could append the rows into dataframe inside the for loop, this impacts performance negatively, because it doubles the memory requirements.\n",
    "This is because the data frame which is being appended to as well as the chunk is typecasted as dataframe. \n",
    "A simpler approach is to build a list in memory and append all the records inside the loop.\n",
    "Post loop, convert the list to dataframe. \n",
    "'''\n",
    "csv_handle = pd.read_csv('./Datasets/CityList.csv', chunksize=10000)\n",
    "csv_data_lst = []\n",
    "for i in csv_handle:\n",
    "    csv_data_lst.append(i)\n",
    "\n",
    "csv_df = pd.concat(csv_data_lst)\n",
    "csv_df.head()\n",
    "csv_df.shape    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>CountryCode</th>\n",
       "      <th>Population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kabul</td>\n",
       "      <td>AFG</td>\n",
       "      <td>1780000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Qandahar</td>\n",
       "      <td>AFG</td>\n",
       "      <td>237500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>NLD</td>\n",
       "      <td>731200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Utrecht</td>\n",
       "      <td>NLD</td>\n",
       "      <td>234323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eindhoven</td>\n",
       "      <td>NLD</td>\n",
       "      <td>201843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Name CountryCode  Population\n",
       "0      Kabul         AFG     1780000\n",
       "1   Qandahar         AFG      237500\n",
       "2  Amsterdam         NLD      731200\n",
       "3    Utrecht         NLD      234323\n",
       "4  Eindhoven         NLD      201843"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "'''\n",
    "Uses the build-in read_json method from the pandas package. While this is OK for small files, this is not recommended for large file due to schema replication per record.\n",
    "An Avro format is much better. \n",
    "'''\n",
    "json_df = pd.read_json('./Datasets/CityListA.json')\n",
    "print(json_df.shape)\n",
    "json_df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'record', 'name': 'exercise_avro.citylistB', 'fields': [{'name': 'name', 'type': 'string'}, {'name': 'code', 'type': 'string'}, {'name': 'Population', 'type': 'long'}], '__fastavro_parsed': True, '__named_schemas': {'exercise_avro.citylistB': {'type': 'record', 'name': 'exercise_avro.citylistB', 'fields': [{'name': 'name', 'type': 'string'}, {'name': 'code', 'type': 'string'}, {'name': 'Population', 'type': 'long'}]}}}\n",
      "583\n",
      "(583, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>CountryCode</th>\n",
       "      <th>Population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mazar-e-Sharif</td>\n",
       "      <td>AFG</td>\n",
       "      <td>127800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Groningen</td>\n",
       "      <td>NLD</td>\n",
       "      <td>172701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arnhem</td>\n",
       "      <td>NLD</td>\n",
       "      <td>138020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Haarlemmermeer</td>\n",
       "      <td>NLD</td>\n",
       "      <td>110722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alkmaar</td>\n",
       "      <td>NLD</td>\n",
       "      <td>92713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Name CountryCode  Population\n",
       "0  Mazar-e-Sharif         AFG      127800\n",
       "1       Groningen         NLD      172701\n",
       "2          Arnhem         NLD      138020\n",
       "3  Haarlemmermeer         NLD      110722\n",
       "4         Alkmaar         NLD       92713"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fastavro import writer, reader, parse_schema\n",
    "import pandas as pd\n",
    "'''\n",
    "Importing pandas multiple times is redundant.\n",
    "Using the fastavro package.\n",
    "I have defined a schema for the file and validated using parse_schema().\n",
    "\n",
    "Like the CSV file approach, I read chunks of Avro file, and build a list inside the loop.\n",
    "Post loop, I can cast the list as a dataframe.\n",
    "'''\n",
    "av_schema = {\n",
    "    \"type\" : \"record\",\n",
    "    \"namespace\" : \"exercise_avro\",\n",
    "    \"name\" : \"citylistB\",\n",
    "    \"fields\" :[\n",
    "        {\"name\": \"name\", \"type\": \"string\" },\n",
    "        {\"name\": \"code\", \"type\": \"string\" },\n",
    "        {\"name\": \"Population\", \"type\": \"long\" },\n",
    "    ]\n",
    "}\n",
    "\n",
    "av_schema_check = parse_schema(av_schema)\n",
    "print(av_schema_check)\n",
    "\n",
    "av_data_lst = []\n",
    "with open('./Datasets/CityListB.avro', 'rb') as city_av:\n",
    "    for i in reader(city_av):\n",
    "        av_data_lst.append(i)\n",
    "\n",
    "print(len(av_data_lst)) \n",
    "\n",
    "avro_df = pd.DataFrame(av_data_lst)\n",
    "print(avro_df.shape)\n",
    "avro_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2583, 3)\n",
      "                        Name CountryCode  Population\n",
      "235                   Å umen         BGR       94686\n",
      "993                  Å ostka         UKR       90000\n",
      "699                Å iauliai         LTU      146563\n",
      "523                   Å ahty         RUS      221800\n",
      "967                   Ã‡orum         TUR      145495\n",
      "129  Ãguas Lindas de GoiÃ¡s         BRA       89200\n",
      "766                 al-Zarqa         JOR      389815\n",
      "910                 al-Tuqba         SAU      125700\n",
      "907                  al-Taif         SAU      416100\n",
      "587           al-Sulaymaniya         IRQ      364096\n",
      "(2083, 3)\n",
      "Index           16664\n",
      "Name           144414\n",
      "CountryCode    124980\n",
      "Population      16664\n",
      "dtype: int64\n",
      "26390\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Using pandas concat() method to combine the 3 datarames and exporting a file to allow visual inspection.\n",
    "Using drop_duplicates() to remove record duplicates and exporting to a file for inspection. \n",
    "Using sort_values() method to sort data by City Names, alphabetically.\n",
    "Memory analysis for dataframe columns, e.g. CountryCode String --> Categorical\n",
    "'''\n",
    "combined_df1 = pd.concat([csv_df,json_df,avro_df])\n",
    "print(combined_df1.shape)\n",
    "combined_df1.to_csv('combined_b4dedup.csv')\n",
    "\n",
    "combined_df1.drop_duplicates(inplace=True)\n",
    "combined_df1.sort_values(by=['Name'], ascending=False, inplace=True)\n",
    "combined_df1.to_csv('combined_a4dedup.csv')\n",
    "\n",
    "print(combined_df1.head(10))\n",
    "print(combined_df1.shape)\n",
    "print(combined_df1.memory_usage(deep=True))\n",
    "print(combined_df1['CountryCode'].astype('category').memory_usage())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the count of all rows? \n",
      " 2083\n",
      "What is the city with the largest population? \n",
      "                 Name CountryCode  Population\n",
      "439  Mumbai (Bombay)         IND    10500000\n",
      "What is the total population of all cities in Brazil (CountryCode == BRA)? \n",
      " 55955012\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Exercise Questions\n",
    "Q1: What is the count of all rows?\n",
    "Q2: What is the city with the largest population?\n",
    "Q3: What is the total population of all cities in Brazil (CountryCode == BRA)?\n",
    "'''\n",
    "print(f\"What is the count of all rows? \\n\",len(combined_df1.index))\n",
    "print(f\"What is the city with the largest population? \\n\", combined_df1[combined_df1['Population'] == combined_df1['Population'].max()])\n",
    "print(f\"What is the total population of all cities in Brazil (CountryCode == BRA)? \\n\", combined_df1.loc[combined_df1.CountryCode == 'BRA', 'Population'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4: What changes could be made to improve your program's performance?\\\n",
    "A4: Choice of better file formats and datatypes. AVRO over JSON, and convert and store CountryCode as a Categorical.  \n",
    "\n",
    "Q5: How would you scale your solution to a much larger dataset (too large for a single machine to store)?\\\n",
    "A5: we could use dask library to load large files in parallel, along with Spark to hold teh distributed set in memory till it is committed to a durable storage.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
